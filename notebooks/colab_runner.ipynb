{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "904zHNhPsl7H"
      },
      "source": [
        "# T&C Summarization - Colab Runner\n",
        "\n",
        "Use this notebook to run the training and evaluation remotely on Google Colab (with free GPU)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLFr2AIRsl7I"
      },
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIMpT9PQsl7I",
        "outputId": "2b0e197d-6f73-4523-fbb4-6b037dec9761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TandC_Summarisation'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 23 (delta 3), reused 21 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (23/23), 815.66 KiB | 21.46 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "/content/TandC_Summarisation\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/SreeVarshinii/TandC_Summarisation.git\n",
        "%cd TandC_Summarisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n17qy8gjsl7J",
        "outputId": "8fbfa173-de48-466f-84e0-04b7de54aecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (4.57.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (3.8.11)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (0.2.1)\n",
            "Collecting textstat (from -r requirements.txt (line 6))\n",
            "  Downloading textstat-0.7.11-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting rouge-score (from -r requirements.txt (line 7))\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (4.67.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (4.0.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (18.1.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 3)) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 3)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 3)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 3)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 3)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 3)) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 4)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 4)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 4)) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 4)) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 4)) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 4)) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 4)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 4)) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 4)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 4)) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 4)) (0.20.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 4)) (2.12.3)\n",
            "Collecting pyphen (from textstat->-r requirements.txt (line 6))\n",
            "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from textstat->-r requirements.txt (line 6)) (3.9.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score->-r requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 9)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 9)) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 9)) (0.70.16)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 9)) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 4)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 4)) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 4)) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 4)) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy->-r requirements.txt (line 4)) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy->-r requirements.txt (line 4)) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 2)) (3.0.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->textstat->-r requirements.txt (line 6)) (1.5.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 9)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 9)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 9)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 9)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 9)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 9)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 9)) (1.22.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy->-r requirements.txt (line 4)) (2.0.1)\n",
            "Downloading textstat-0.7.11-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=8f053276a8461d842e22927e943a0accdc2d50374963039a9070438576c9fe13\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: pyphen, textstat, rouge-score\n",
            "Successfully installed pyphen-0.17.2 rouge-score-0.1.2 textstat-0.7.11\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w7sIKXhsl7J"
      },
      "source": [
        "## 2. Verify Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-ml09jlsl7J",
        "outputId": "3524fbda-3463-4aea-d650-b6ac6d5cdb08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data found!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if os.path.exists('data/training/augmented_train.parquet'):\n",
        "    print(\"Training data found!\")\n",
        "else:\n",
        "    print(\"Training data NOT found. You may need to run src/prepare_training_data.py or upload the data.\")\n",
        "    # Attempting to run preparation if needed (requires raw data which might NOT be in git)\n",
        "    # !python src/prepare_training_data.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0PBGDMEsl7J"
      },
      "source": [
        "## 3. Run Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i6bV3mtsl7K",
        "outputId": "0b5063ae-0fc8-4e01-a4d3-ad1be1dedd06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-08 06:43:33.573559: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-08 06:43:33.591643: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765176213.613365    1738 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765176213.619819    1738 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765176213.636346    1738 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765176213.636379    1738 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765176213.636382    1738 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765176213.636385    1738 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-08 06:43:33.641536: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading model: google/flan-t5-base...\n",
            "tokenizer_config.json: 2.54kB [00:00, 16.1MB/s]\n",
            "spiece.model: 100% 792k/792k [00:00<00:00, 1.57MB/s]\n",
            "tokenizer.json: 2.42MB [00:00, 101MB/s]\n",
            "special_tokens_map.json: 2.20kB [00:00, 17.3MB/s]\n",
            "config.json: 1.40kB [00:00, 11.5MB/s]\n",
            "model.safetensors: 100% 990M/990M [00:01<00:00, 639MB/s] \n",
            "generation_config.json: 100% 147/147 [00:00<00:00, 1.60MB/s]\n",
            "Loading data from data/training/augmented_train.parquet...\n",
            "Tokenizing data...\n",
            "Map: 100% 100/100 [00:00<00:00, 612.14 examples/s]\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "/content/TandC_Summarisation/src/train.py:58: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n",
            "Starting training...\n",
            "{'loss': 2.7206, 'grad_norm': 3.9457895755767822, 'learning_rate': 2e-05, 'epoch': 0.04}\n",
            "{'loss': 2.6636, 'grad_norm': 2.7911288738250732, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.09}\n",
            " 40% 2/5 [00:02<00:03,  1.19s/it]\n",
            "  0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 40% 4/10 [00:00<00:00, 31.37it/s]\u001b[A\n",
            "                                 \n",
            "\u001b[A{'eval_loss': 2.217559337615967, 'eval_runtime': 0.4323, 'eval_samples_per_second': 23.131, 'eval_steps_per_second': 23.131, 'epoch': 0.09}\n",
            " 40% 2/5 [00:03<00:03,  1.19s/it]\n",
            "100% 10/10 [00:00<00:00, 25.92it/s]\u001b[A\n",
            "{'loss': 2.5822, 'grad_norm': 3.3020546436309814, 'learning_rate': 1.2e-05, 'epoch': 0.13}\n",
            "{'loss': 2.8266, 'grad_norm': 3.6334314346313477, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.18}\n",
            " 80% 4/5 [00:04<00:00,  1.09it/s]\n",
            "  0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 40% 4/10 [00:00<00:00, 31.10it/s]\u001b[A\n",
            "                                 \n",
            "\u001b[A{'eval_loss': 2.1914024353027344, 'eval_runtime': 0.4285, 'eval_samples_per_second': 23.339, 'eval_steps_per_second': 23.339, 'epoch': 0.18}\n",
            " 80% 4/5 [00:04<00:00,  1.09it/s]\n",
            "100% 10/10 [00:00<00:00, 26.25it/s]\u001b[A\n",
            "{'loss': 2.5199, 'grad_norm': 2.2851991653442383, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.22}\n",
            "{'train_runtime': 9.4477, 'train_samples_per_second': 2.117, 'train_steps_per_second': 0.529, 'train_loss': 2.6625940799713135, 'epoch': 0.22}\n",
            "100% 5/5 [00:09<00:00,  1.89s/it]\n",
            "Saving model to models/flan-t5-legal-explained...\n"
          ]
        }
      ],
      "source": [
        "# Run training script\n",
        "# Ensure you have selected a Runtime > Change runtime type > GPU\n",
        "!python src/train.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AjKc_ygsl7K"
      },
      "source": [
        "## 4. Run Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKn07Qdysl7K",
        "outputId": "49bb17fd-d798-42b9-8e13-48f2335592a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Flan-T5 (Our System)...\n",
            "Loading model: google/flan-t5-base...\n",
            "2025-12-08 06:48:24.966223: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-08 06:48:24.984465: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765176505.006545    3243 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765176505.013292    3243 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765176505.030248    3243 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765176505.030276    3243 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765176505.030280    3243 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765176505.030282    3243 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-08 06:48:25.035224: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Model loaded on cuda.\n",
            "Loaded glossary with 50 terms.\n",
            "Loading BART (Baseline)...\n",
            "\n",
            "--- Running Comparison on 5 samples ---\n",
            "100% 5/5 [00:13<00:00,  2.73s/it]\n",
            "\n",
            "--- Aggregated Results ---\n",
            "                       rouge1   rougeL  grade_level  explanation_count\n",
            "model                                                                 \n",
            "BART                  0.26792  0.19584    12.885945                0.6\n",
            "Flan-T5 (No Explain)  0.18276  0.12880    12.669661                0.6\n",
            "Flan-T5 + Explain     0.18260  0.12872    12.714653                0.8\n",
            "\n",
            "Detailed results saved to comparison_results.csv\n"
          ]
        }
      ],
      "source": [
        "!python src/compare_models.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git branch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ErxRyc2tAOI",
        "outputId": "f04b6185-768d-42e6-8ed3-269797de51be"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* \u001b[32mmain\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -b new_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUuKJ90Oydpr",
        "outputId": "73c46d4f-9942-4930-dd07-f4b0337738cf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: A branch named 'new_data' already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git branch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2Oj3MnG0GkF",
        "outputId": "cb6375ee-01ac-46b1-9126-a0450aefad15"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  main\u001b[m\n",
            "* \u001b[32mnew_data\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull origin new_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEdYK_z40HL-",
        "outputId": "ef32cb49-2f72-4b1c-f861-fa20f23c5d35"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  25% (1/4)\rUnpacking objects:  50% (2/4)\rUnpacking objects:  75% (3/4)\rUnpacking objects: 100% (4/4)\rUnpacking objects: 100% (4/4), 1.66 KiB | 1.66 MiB/s, done.\n",
            "From https://github.com/SreeVarshinii/TandC_Summarisation\n",
            " * branch            new_data   -> FETCH_HEAD\n",
            "   2045f7f..b3f418a  new_data   -> origin/new_data\n",
            "Updating 2045f7f..b3f418a\n",
            "Fast-forward\n",
            " src/compare_models.py | 81 \u001b[32m+++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m------------\u001b[m\n",
            " 1 file changed, 62 insertions(+), 19 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDkU0NnL0VIh",
        "outputId": "b96b35ad-4aef-4831-f109-ca22f5b7aefa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch new_data\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mmodels/\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/train.py --model_name \"models/flan-t5-legal-explained\" --data_path \"data/training/kaggle_legal_augmented.parquet\" --output_dir \"models/flan-t5-kaggle-final\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pxRRFud1QjT",
        "outputId": "aae7be01-0ab6-4033-9d52-378612233146"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-08 07:21:22.243538: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-08 07:21:22.261392: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765178482.283164   11453 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765178482.290002   11453 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765178482.306635   11453 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765178482.306666   11453 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765178482.306669   11453 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765178482.306672   11453 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-08 07:21:22.311701: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading model: models/flan-t5-legal-explained...\n",
            "Loading data from data/training/kaggle_legal_augmented.parquet...\n",
            "Tokenizing data...\n",
            "Map: 100% 7821/7821 [00:20<00:00, 382.53 examples/s]\n",
            "Using existing splits...\n",
            "Filter: 100% 7821/7821 [00:09<00:00, 861.76 examples/s]\n",
            "Filter: 100% 7821/7821 [00:09<00:00, 855.50 examples/s]\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "/content/TandC_Summarisation/src/train.py:80: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n",
            "Starting training on 7721 samples...\n",
            "{'loss': 2.8362, 'grad_norm': 0.7618480324745178, 'learning_rate': 1.966183574879227e-05, 'epoch': 0.05}\n",
            "{'loss': 2.7437, 'grad_norm': 0.7434737086296082, 'learning_rate': 1.9316770186335406e-05, 'epoch': 0.1}\n",
            "{'loss': 2.6818, 'grad_norm': 0.7295796275138855, 'learning_rate': 1.8971704623878537e-05, 'epoch': 0.16}\n",
            "{'loss': 2.6867, 'grad_norm': 0.6732758283615112, 'learning_rate': 1.862663906142167e-05, 'epoch': 0.21}\n",
            "{'loss': 2.6459, 'grad_norm': 0.8374833464622498, 'learning_rate': 1.8281573498964803e-05, 'epoch': 0.26}\n",
            "{'loss': 2.6125, 'grad_norm': 0.6667196154594421, 'learning_rate': 1.7936507936507937e-05, 'epoch': 0.31}\n",
            "{'loss': 2.5937, 'grad_norm': 0.6981863379478455, 'learning_rate': 1.759144237405107e-05, 'epoch': 0.36}\n",
            "{'loss': 2.5384, 'grad_norm': 0.7955964207649231, 'learning_rate': 1.7246376811594206e-05, 'epoch': 0.41}\n",
            "{'loss': 2.5297, 'grad_norm': 0.7134155631065369, 'learning_rate': 1.6901311249137337e-05, 'epoch': 0.47}\n",
            "{'loss': 2.5191, 'grad_norm': 0.7195718288421631, 'learning_rate': 1.655624568668047e-05, 'epoch': 0.52}\n",
            " 17% 500/2898 [11:07<51:52,  1.30s/it]\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/50 [00:00<00:02, 19.46it/s]\u001b[A\n",
            "  8% 4/50 [00:00<00:03, 13.89it/s]\u001b[A\n",
            " 12% 6/50 [00:00<00:03, 11.20it/s]\u001b[A\n",
            " 16% 8/50 [00:00<00:04, 10.15it/s]\u001b[A\n",
            " 20% 10/50 [00:00<00:04,  9.37it/s]\u001b[A\n",
            " 22% 11/50 [00:01<00:04,  9.12it/s]\u001b[A\n",
            " 24% 12/50 [00:01<00:04,  9.02it/s]\u001b[A\n",
            " 26% 13/50 [00:01<00:04,  8.85it/s]\u001b[A\n",
            " 28% 14/50 [00:01<00:04,  8.80it/s]\u001b[A\n",
            " 30% 15/50 [00:01<00:04,  8.67it/s]\u001b[A\n",
            " 34% 17/50 [00:01<00:03,  9.39it/s]\u001b[A\n",
            " 38% 19/50 [00:01<00:03,  9.39it/s]\u001b[A\n",
            " 40% 20/50 [00:02<00:03,  9.24it/s]\u001b[A\n",
            " 44% 22/50 [00:02<00:03,  9.30it/s]\u001b[A\n",
            " 48% 24/50 [00:02<00:02,  9.34it/s]\u001b[A\n",
            " 50% 25/50 [00:02<00:02,  9.11it/s]\u001b[A\n",
            " 52% 26/50 [00:02<00:02,  8.92it/s]\u001b[A\n",
            " 54% 27/50 [00:02<00:02,  8.75it/s]\u001b[A\n",
            " 56% 28/50 [00:02<00:02,  8.65it/s]\u001b[A\n",
            " 58% 29/50 [00:03<00:02,  8.56it/s]\u001b[A\n",
            " 60% 30/50 [00:03<00:02,  8.52it/s]\u001b[A\n",
            " 62% 31/50 [00:03<00:02,  8.44it/s]\u001b[A\n",
            " 64% 32/50 [00:03<00:02,  8.41it/s]\u001b[A\n",
            " 66% 33/50 [00:03<00:02,  8.38it/s]\u001b[A\n",
            " 68% 34/50 [00:03<00:01,  8.34it/s]\u001b[A\n",
            " 70% 35/50 [00:03<00:01,  8.33it/s]\u001b[A\n",
            " 72% 36/50 [00:03<00:01,  8.28it/s]\u001b[A\n",
            " 74% 37/50 [00:04<00:01,  8.33it/s]\u001b[A\n",
            " 76% 38/50 [00:04<00:01,  8.30it/s]\u001b[A\n",
            " 80% 40/50 [00:04<00:01,  9.37it/s]\u001b[A\n",
            " 82% 41/50 [00:04<00:00,  9.08it/s]\u001b[A\n",
            " 86% 43/50 [00:04<00:00,  9.47it/s]\u001b[A\n",
            " 88% 44/50 [00:04<00:00,  9.17it/s]\u001b[A\n",
            " 90% 45/50 [00:04<00:00,  8.95it/s]\u001b[A\n",
            " 92% 46/50 [00:05<00:00,  8.76it/s]\u001b[A\n",
            " 94% 47/50 [00:05<00:00,  8.65it/s]\u001b[A\n",
            " 96% 48/50 [00:05<00:00,  8.55it/s]\u001b[A\n",
            " 98% 49/50 [00:05<00:00,  8.48it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.3931586742401123, 'eval_runtime': 5.6238, 'eval_samples_per_second': 17.782, 'eval_steps_per_second': 8.891, 'epoch': 0.52}\n",
            " 17% 500/2898 [11:13<51:52,  1.30s/it]\n",
            "100% 50/50 [00:05<00:00,  8.52it/s]\u001b[A\n",
            "{'loss': 2.5152, 'grad_norm': 0.8320789337158203, 'learning_rate': 1.6211180124223606e-05, 'epoch': 0.57}\n",
            "{'loss': 2.533, 'grad_norm': 0.6884965896606445, 'learning_rate': 1.5866114561766737e-05, 'epoch': 0.62}\n",
            "{'loss': 2.5001, 'grad_norm': 0.7836073040962219, 'learning_rate': 1.552104899930987e-05, 'epoch': 0.67}\n",
            "{'loss': 2.52, 'grad_norm': 0.6763156652450562, 'learning_rate': 1.5175983436853004e-05, 'epoch': 0.73}\n",
            "{'loss': 2.5121, 'grad_norm': 0.6532737612724304, 'learning_rate': 1.4830917874396135e-05, 'epoch': 0.78}\n",
            "{'loss': 2.4373, 'grad_norm': 0.6878377199172974, 'learning_rate': 1.448585231193927e-05, 'epoch': 0.83}\n",
            "{'loss': 2.4557, 'grad_norm': 0.72659832239151, 'learning_rate': 1.4140786749482403e-05, 'epoch': 0.88}\n",
            "{'loss': 2.51, 'grad_norm': 0.7442845702171326, 'learning_rate': 1.3795721187025537e-05, 'epoch': 0.93}\n",
            "{'loss': 2.4686, 'grad_norm': 0.6770225167274475, 'learning_rate': 1.345065562456867e-05, 'epoch': 0.98}\n",
            "{'loss': 2.4622, 'grad_norm': 0.958430826663971, 'learning_rate': 1.31055900621118e-05, 'epoch': 1.04}\n",
            " 35% 1000/2898 [22:18<42:48,  1.35s/it]\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/50 [00:00<00:02, 19.27it/s]\u001b[A\n",
            "  8% 4/50 [00:00<00:03, 13.71it/s]\u001b[A\n",
            " 12% 6/50 [00:00<00:03, 11.21it/s]\u001b[A\n",
            " 16% 8/50 [00:00<00:04, 10.10it/s]\u001b[A\n",
            " 20% 10/50 [00:00<00:04,  9.40it/s]\u001b[A\n",
            " 22% 11/50 [00:01<00:04,  9.18it/s]\u001b[A\n",
            " 24% 12/50 [00:01<00:04,  8.97it/s]\u001b[A\n",
            " 26% 13/50 [00:01<00:04,  8.78it/s]\u001b[A\n",
            " 28% 14/50 [00:01<00:04,  8.71it/s]\u001b[A\n",
            " 30% 15/50 [00:01<00:04,  8.66it/s]\u001b[A\n",
            " 32% 16/50 [00:01<00:03,  8.97it/s]\u001b[A\n",
            " 36% 18/50 [00:01<00:03,  9.80it/s]\u001b[A\n",
            " 38% 19/50 [00:01<00:03,  9.38it/s]\u001b[A\n",
            " 40% 20/50 [00:02<00:03,  9.16it/s]\u001b[A\n",
            " 44% 22/50 [00:02<00:02,  9.35it/s]\u001b[A\n",
            " 48% 24/50 [00:02<00:02,  9.32it/s]\u001b[A\n",
            " 50% 25/50 [00:02<00:02,  9.09it/s]\u001b[A\n",
            " 52% 26/50 [00:02<00:02,  8.86it/s]\u001b[A\n",
            " 54% 27/50 [00:02<00:02,  8.74it/s]\u001b[A\n",
            " 56% 28/50 [00:02<00:02,  8.62it/s]\u001b[A\n",
            " 58% 29/50 [00:03<00:02,  8.54it/s]\u001b[A\n",
            " 60% 30/50 [00:03<00:02,  8.51it/s]\u001b[A\n",
            " 62% 31/50 [00:03<00:02,  8.44it/s]\u001b[A\n",
            " 64% 32/50 [00:03<00:02,  8.34it/s]\u001b[A\n",
            " 66% 33/50 [00:03<00:02,  8.37it/s]\u001b[A\n",
            " 68% 34/50 [00:03<00:01,  8.34it/s]\u001b[A\n",
            " 70% 35/50 [00:03<00:01,  8.34it/s]\u001b[A\n",
            " 72% 36/50 [00:03<00:01,  8.32it/s]\u001b[A\n",
            " 74% 37/50 [00:04<00:01,  8.33it/s]\u001b[A\n",
            " 76% 38/50 [00:04<00:01,  8.33it/s]\u001b[A\n",
            " 80% 40/50 [00:04<00:01,  9.35it/s]\u001b[A\n",
            " 82% 41/50 [00:04<00:00,  9.05it/s]\u001b[A\n",
            " 86% 43/50 [00:04<00:00,  9.46it/s]\u001b[A\n",
            " 88% 44/50 [00:04<00:00,  9.12it/s]\u001b[A\n",
            " 90% 45/50 [00:04<00:00,  8.95it/s]\u001b[A\n",
            " 92% 46/50 [00:05<00:00,  8.78it/s]\u001b[A\n",
            " 94% 47/50 [00:05<00:00,  8.63it/s]\u001b[A\n",
            " 96% 48/50 [00:05<00:00,  8.53it/s]\u001b[A\n",
            " 98% 49/50 [00:05<00:00,  8.48it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.3326430320739746, 'eval_runtime': 5.6294, 'eval_samples_per_second': 17.764, 'eval_steps_per_second': 8.882, 'epoch': 1.04}\n",
            " 35% 1000/2898 [22:24<42:48,  1.35s/it]\n",
            "100% 50/50 [00:05<00:00,  8.51it/s]\u001b[A\n",
            "{'loss': 2.4653, 'grad_norm': 0.6807287931442261, 'learning_rate': 1.2760524499654935e-05, 'epoch': 1.09}\n",
            "{'loss': 2.4318, 'grad_norm': 0.6367520093917847, 'learning_rate': 1.2415458937198068e-05, 'epoch': 1.14}\n",
            "{'loss': 2.4333, 'grad_norm': 0.578325629234314, 'learning_rate': 1.2070393374741203e-05, 'epoch': 1.19}\n",
            "{'loss': 2.4572, 'grad_norm': 0.7392560839653015, 'learning_rate': 1.1725327812284335e-05, 'epoch': 1.24}\n",
            "{'loss': 2.4086, 'grad_norm': 0.717519223690033, 'learning_rate': 1.1380262249827468e-05, 'epoch': 1.29}\n",
            "{'loss': 2.439, 'grad_norm': 0.8733971118927002, 'learning_rate': 1.1035196687370603e-05, 'epoch': 1.35}\n",
            "{'loss': 2.4568, 'grad_norm': 0.6969101428985596, 'learning_rate': 1.0690131124913734e-05, 'epoch': 1.4}\n",
            "{'loss': 2.4404, 'grad_norm': 0.6708499789237976, 'learning_rate': 1.0345065562456868e-05, 'epoch': 1.45}\n",
            "{'loss': 2.4058, 'grad_norm': 0.8061233758926392, 'learning_rate': 1e-05, 'epoch': 1.5}\n",
            "{'loss': 2.4335, 'grad_norm': 0.8155356049537659, 'learning_rate': 9.654934437543134e-06, 'epoch': 1.55}\n",
            " 52% 1500/2898 [33:32<30:27,  1.31s/it]\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/50 [00:00<00:02, 19.05it/s]\u001b[A\n",
            "  8% 4/50 [00:00<00:03, 13.72it/s]\u001b[A\n",
            " 12% 6/50 [00:00<00:03, 11.17it/s]\u001b[A\n",
            " 16% 8/50 [00:00<00:04, 10.09it/s]\u001b[A\n",
            " 20% 10/50 [00:00<00:04,  9.26it/s]\u001b[A\n",
            " 22% 11/50 [00:01<00:04,  9.19it/s]\u001b[A\n",
            " 24% 12/50 [00:01<00:04,  8.98it/s]\u001b[A\n",
            " 26% 13/50 [00:01<00:04,  8.81it/s]\u001b[A\n",
            " 28% 14/50 [00:01<00:04,  8.78it/s]\u001b[A\n",
            " 30% 15/50 [00:01<00:04,  8.64it/s]\u001b[A\n",
            " 34% 17/50 [00:01<00:03,  9.25it/s]\u001b[A\n",
            " 38% 19/50 [00:01<00:03,  9.44it/s]\u001b[A\n",
            " 40% 20/50 [00:02<00:03,  9.27it/s]\u001b[A\n",
            " 44% 22/50 [00:02<00:02,  9.37it/s]\u001b[A\n",
            " 48% 24/50 [00:02<00:02,  9.34it/s]\u001b[A\n",
            " 50% 25/50 [00:02<00:02,  9.10it/s]\u001b[A\n",
            " 52% 26/50 [00:02<00:02,  8.92it/s]\u001b[A\n",
            " 54% 27/50 [00:02<00:02,  8.74it/s]\u001b[A\n",
            " 56% 28/50 [00:02<00:02,  8.62it/s]\u001b[A\n",
            " 58% 29/50 [00:03<00:02,  8.54it/s]\u001b[A\n",
            " 60% 30/50 [00:03<00:02,  8.49it/s]\u001b[A\n",
            " 62% 31/50 [00:03<00:02,  8.45it/s]\u001b[A\n",
            " 64% 32/50 [00:03<00:02,  8.40it/s]\u001b[A\n",
            " 66% 33/50 [00:03<00:02,  8.34it/s]\u001b[A\n",
            " 68% 34/50 [00:03<00:01,  8.34it/s]\u001b[A\n",
            " 70% 35/50 [00:03<00:01,  8.33it/s]\u001b[A\n",
            " 72% 36/50 [00:03<00:01,  8.31it/s]\u001b[A\n",
            " 74% 37/50 [00:04<00:01,  8.34it/s]\u001b[A\n",
            " 76% 38/50 [00:04<00:01,  8.29it/s]\u001b[A\n",
            " 80% 40/50 [00:04<00:01,  9.28it/s]\u001b[A\n",
            " 82% 41/50 [00:04<00:00,  9.04it/s]\u001b[A\n",
            " 86% 43/50 [00:04<00:00,  9.45it/s]\u001b[A\n",
            " 88% 44/50 [00:04<00:00,  9.16it/s]\u001b[A\n",
            " 90% 45/50 [00:04<00:00,  8.86it/s]\u001b[A\n",
            " 92% 46/50 [00:05<00:00,  8.72it/s]\u001b[A\n",
            " 94% 47/50 [00:05<00:00,  8.62it/s]\u001b[A\n",
            " 96% 48/50 [00:05<00:00,  8.53it/s]\u001b[A\n",
            " 98% 49/50 [00:05<00:00,  8.46it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.3016207218170166, 'eval_runtime': 5.6358, 'eval_samples_per_second': 17.744, 'eval_steps_per_second': 8.872, 'epoch': 1.55}\n",
            " 52% 1500/2898 [33:38<30:27,  1.31s/it]\n",
            "100% 50/50 [00:05<00:00,  8.49it/s]\u001b[A\n",
            "{'loss': 2.4261, 'grad_norm': 0.8651257753372192, 'learning_rate': 9.309868875086268e-06, 'epoch': 1.61}\n",
            "{'loss': 2.4024, 'grad_norm': 0.8656449913978577, 'learning_rate': 8.964803312629399e-06, 'epoch': 1.66}\n",
            "{'loss': 2.3891, 'grad_norm': 0.779435396194458, 'learning_rate': 8.619737750172534e-06, 'epoch': 1.71}\n",
            "{'loss': 2.4297, 'grad_norm': 0.766266405582428, 'learning_rate': 8.274672187715666e-06, 'epoch': 1.76}\n",
            "{'loss': 2.4538, 'grad_norm': 0.8039397597312927, 'learning_rate': 7.9296066252588e-06, 'epoch': 1.81}\n",
            "{'loss': 2.3851, 'grad_norm': 0.6055313348770142, 'learning_rate': 7.584541062801934e-06, 'epoch': 1.86}\n",
            "{'loss': 2.4156, 'grad_norm': 0.6473417282104492, 'learning_rate': 7.2394755003450655e-06, 'epoch': 1.92}\n",
            "{'loss': 2.4196, 'grad_norm': 0.7507883310317993, 'learning_rate': 6.894409937888199e-06, 'epoch': 1.97}\n",
            "{'loss': 2.456, 'grad_norm': 0.6389470100402832, 'learning_rate': 6.549344375431333e-06, 'epoch': 2.02}\n",
            "{'loss': 2.4074, 'grad_norm': 0.6494154930114746, 'learning_rate': 6.2042788129744655e-06, 'epoch': 2.07}\n",
            " 69% 2000/2898 [44:44<19:57,  1.33s/it]\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/50 [00:00<00:02, 19.25it/s]\u001b[A\n",
            "  8% 4/50 [00:00<00:03, 13.88it/s]\u001b[A\n",
            " 12% 6/50 [00:00<00:03, 11.14it/s]\u001b[A\n",
            " 16% 8/50 [00:00<00:04, 10.14it/s]\u001b[A\n",
            " 20% 10/50 [00:00<00:04,  9.43it/s]\u001b[A\n",
            " 22% 11/50 [00:01<00:04,  9.18it/s]\u001b[A\n",
            " 24% 12/50 [00:01<00:04,  8.99it/s]\u001b[A\n",
            " 26% 13/50 [00:01<00:04,  8.80it/s]\u001b[A\n",
            " 28% 14/50 [00:01<00:04,  8.75it/s]\u001b[A\n",
            " 30% 15/50 [00:01<00:04,  8.65it/s]\u001b[A\n",
            " 32% 16/50 [00:01<00:03,  8.99it/s]\u001b[A\n",
            " 36% 18/50 [00:01<00:03,  9.80it/s]\u001b[A\n",
            " 38% 19/50 [00:01<00:03,  9.39it/s]\u001b[A\n",
            " 40% 20/50 [00:02<00:03,  9.19it/s]\u001b[A\n",
            " 44% 22/50 [00:02<00:02,  9.37it/s]\u001b[A\n",
            " 48% 24/50 [00:02<00:02,  9.26it/s]\u001b[A\n",
            " 50% 25/50 [00:02<00:02,  9.10it/s]\u001b[A\n",
            " 52% 26/50 [00:02<00:02,  8.88it/s]\u001b[A\n",
            " 54% 27/50 [00:02<00:02,  8.72it/s]\u001b[A\n",
            " 56% 28/50 [00:02<00:02,  8.62it/s]\u001b[A\n",
            " 58% 29/50 [00:03<00:02,  8.46it/s]\u001b[A\n",
            " 60% 30/50 [00:03<00:02,  8.50it/s]\u001b[A\n",
            " 62% 31/50 [00:03<00:02,  8.44it/s]\u001b[A\n",
            " 64% 32/50 [00:03<00:02,  8.36it/s]\u001b[A\n",
            " 66% 33/50 [00:03<00:02,  8.39it/s]\u001b[A\n",
            " 68% 34/50 [00:03<00:01,  8.34it/s]\u001b[A\n",
            " 70% 35/50 [00:03<00:01,  8.31it/s]\u001b[A\n",
            " 72% 36/50 [00:03<00:01,  8.32it/s]\u001b[A\n",
            " 74% 37/50 [00:04<00:01,  8.32it/s]\u001b[A\n",
            " 76% 38/50 [00:04<00:01,  8.33it/s]\u001b[A\n",
            " 80% 40/50 [00:04<00:01,  9.33it/s]\u001b[A\n",
            " 82% 41/50 [00:04<00:01,  8.96it/s]\u001b[A\n",
            " 86% 43/50 [00:04<00:00,  9.40it/s]\u001b[A\n",
            " 88% 44/50 [00:04<00:00,  9.15it/s]\u001b[A\n",
            " 90% 45/50 [00:04<00:00,  8.91it/s]\u001b[A\n",
            " 92% 46/50 [00:05<00:00,  8.78it/s]\u001b[A\n",
            " 94% 47/50 [00:05<00:00,  8.63it/s]\u001b[A\n",
            " 96% 48/50 [00:05<00:00,  8.55it/s]\u001b[A\n",
            " 98% 49/50 [00:05<00:00,  8.48it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.2854926586151123, 'eval_runtime': 5.6313, 'eval_samples_per_second': 17.758, 'eval_steps_per_second': 8.879, 'epoch': 2.07}\n",
            " 69% 2000/2898 [44:50<19:57,  1.33s/it]\n",
            "100% 50/50 [00:05<00:00,  8.51it/s]\u001b[A\n",
            "{'loss': 2.4029, 'grad_norm': 0.7002553939819336, 'learning_rate': 5.859213250517599e-06, 'epoch': 2.12}\n",
            "{'loss': 2.4154, 'grad_norm': 0.699020504951477, 'learning_rate': 5.514147688060733e-06, 'epoch': 2.17}\n",
            "{'loss': 2.3498, 'grad_norm': 0.6950993537902832, 'learning_rate': 5.169082125603865e-06, 'epoch': 2.23}\n",
            "{'loss': 2.4015, 'grad_norm': 0.621418833732605, 'learning_rate': 4.824016563146998e-06, 'epoch': 2.28}\n",
            "{'loss': 2.3959, 'grad_norm': 0.7256790995597839, 'learning_rate': 4.478951000690132e-06, 'epoch': 2.33}\n",
            "{'loss': 2.4245, 'grad_norm': 0.579210102558136, 'learning_rate': 4.133885438233265e-06, 'epoch': 2.38}\n",
            "{'loss': 2.3749, 'grad_norm': 0.6253811717033386, 'learning_rate': 3.788819875776398e-06, 'epoch': 2.43}\n",
            "{'loss': 2.396, 'grad_norm': 0.7858520150184631, 'learning_rate': 3.443754313319531e-06, 'epoch': 2.48}\n",
            "{'loss': 2.3873, 'grad_norm': 0.6209303140640259, 'learning_rate': 3.098688750862664e-06, 'epoch': 2.54}\n",
            "{'loss': 2.3932, 'grad_norm': 0.8568459749221802, 'learning_rate': 2.7536231884057974e-06, 'epoch': 2.59}\n",
            " 86% 2500/2898 [55:59<08:47,  1.33s/it]\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/50 [00:00<00:02, 19.18it/s]\u001b[A\n",
            "  8% 4/50 [00:00<00:03, 13.78it/s]\u001b[A\n",
            " 12% 6/50 [00:00<00:03, 11.15it/s]\u001b[A\n",
            " 16% 8/50 [00:00<00:04, 10.11it/s]\u001b[A\n",
            " 20% 10/50 [00:00<00:04,  9.40it/s]\u001b[A\n",
            " 22% 11/50 [00:01<00:04,  9.16it/s]\u001b[A\n",
            " 24% 12/50 [00:01<00:04,  8.96it/s]\u001b[A\n",
            " 26% 13/50 [00:01<00:04,  8.79it/s]\u001b[A\n",
            " 28% 14/50 [00:01<00:04,  8.76it/s]\u001b[A\n",
            " 30% 15/50 [00:01<00:04,  8.65it/s]\u001b[A\n",
            " 34% 17/50 [00:01<00:03,  9.39it/s]\u001b[A\n",
            " 38% 19/50 [00:01<00:03,  9.41it/s]\u001b[A\n",
            " 40% 20/50 [00:02<00:03,  9.26it/s]\u001b[A\n",
            " 44% 22/50 [00:02<00:02,  9.36it/s]\u001b[A\n",
            " 48% 24/50 [00:02<00:02,  9.32it/s]\u001b[A\n",
            " 50% 25/50 [00:02<00:02,  9.12it/s]\u001b[A\n",
            " 52% 26/50 [00:02<00:02,  8.93it/s]\u001b[A\n",
            " 54% 27/50 [00:02<00:02,  8.76it/s]\u001b[A\n",
            " 56% 28/50 [00:02<00:02,  8.64it/s]\u001b[A\n",
            " 58% 29/50 [00:03<00:02,  8.55it/s]\u001b[A\n",
            " 60% 30/50 [00:03<00:02,  8.51it/s]\u001b[A\n",
            " 62% 31/50 [00:03<00:02,  8.44it/s]\u001b[A\n",
            " 64% 32/50 [00:03<00:02,  8.41it/s]\u001b[A\n",
            " 66% 33/50 [00:03<00:02,  8.37it/s]\u001b[A\n",
            " 68% 34/50 [00:03<00:01,  8.36it/s]\u001b[A\n",
            " 70% 35/50 [00:03<00:01,  8.36it/s]\u001b[A\n",
            " 72% 36/50 [00:03<00:01,  8.33it/s]\u001b[A\n",
            " 74% 37/50 [00:04<00:01,  8.35it/s]\u001b[A\n",
            " 76% 38/50 [00:04<00:01,  8.33it/s]\u001b[A\n",
            " 80% 40/50 [00:04<00:01,  9.34it/s]\u001b[A\n",
            " 82% 41/50 [00:04<00:00,  9.04it/s]\u001b[A\n",
            " 86% 43/50 [00:04<00:00,  9.46it/s]\u001b[A\n",
            " 88% 44/50 [00:04<00:00,  9.16it/s]\u001b[A\n",
            " 90% 45/50 [00:04<00:00,  8.93it/s]\u001b[A\n",
            " 92% 46/50 [00:05<00:00,  8.76it/s]\u001b[A\n",
            " 94% 47/50 [00:05<00:00,  8.63it/s]\u001b[A\n",
            " 96% 48/50 [00:05<00:00,  8.53it/s]\u001b[A\n",
            " 98% 49/50 [00:05<00:00,  8.41it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.2757174968719482, 'eval_runtime': 5.6261, 'eval_samples_per_second': 17.774, 'eval_steps_per_second': 8.887, 'epoch': 2.59}\n",
            " 86% 2500/2898 [56:05<08:47,  1.33s/it]\n",
            "100% 50/50 [00:05<00:00,  8.51it/s]\u001b[A\n",
            "{'loss': 2.3816, 'grad_norm': 0.7366504073143005, 'learning_rate': 2.4085576259489306e-06, 'epoch': 2.64}\n",
            "{'loss': 2.3982, 'grad_norm': 0.7297586798667908, 'learning_rate': 2.0634920634920634e-06, 'epoch': 2.69}\n",
            "{'loss': 2.3986, 'grad_norm': 0.6716880202293396, 'learning_rate': 1.718426501035197e-06, 'epoch': 2.74}\n",
            "{'loss': 2.3898, 'grad_norm': 0.7773165702819824, 'learning_rate': 1.37336093857833e-06, 'epoch': 2.8}\n",
            "{'loss': 2.4034, 'grad_norm': 0.5845457911491394, 'learning_rate': 1.0282953761214632e-06, 'epoch': 2.85}\n",
            "{'loss': 2.373, 'grad_norm': 0.7677854895591736, 'learning_rate': 6.832298136645964e-07, 'epoch': 2.9}\n",
            "{'loss': 2.3972, 'grad_norm': 0.6508705019950867, 'learning_rate': 3.3816425120772945e-07, 'epoch': 2.95}\n",
            "{'train_runtime': 3898.1898, 'train_samples_per_second': 5.942, 'train_steps_per_second': 0.743, 'train_loss': 2.464015865918272, 'epoch': 3.0}\n",
            "100% 2898/2898 [1:04:58<00:00,  1.35s/it]\n",
            "Saving model to models/flan-t5-kaggle-final...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/compare_models.py --model_path \"models/flan-t5-legal-explained\" --data_path \"data/training/kaggle_legal_augmented.parquet\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F_6O_f71Vd8",
        "outputId": "c03a4db6-01c7-4fd8-cdbe-67eb1f01b66d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Evaluated Model: models/flan-t5-legal-explained...\n",
            "Loading model: models/flan-t5-legal-explained...\n",
            "2025-12-08 08:30:15.785885: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-08 08:30:15.804194: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765182615.825983   28859 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765182615.832585   28859 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765182615.849441   28859 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765182615.849472   28859 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765182615.849475   28859 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765182615.849477   28859 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-08 08:30:15.854403: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Model loaded on cuda.\n",
            "Loaded glossary with 50 terms.\n",
            "Loading BART (Baseline)...\n",
            "Loading data from data/training/kaggle_legal_augmented.parquet...\n",
            "\n",
            "--- Running Comparison on 5 samples ---\n",
            "100% 5/5 [00:11<00:00,  2.31s/it]\n",
            "\n",
            "--- Aggregated Results ---\n",
            "                                          rouge1  ...  explanation_count\n",
            "model                                             ...                   \n",
            "BART (Baseline)                          0.10516  ...                0.0\n",
            "Fine-Tuned Flan-T5                       0.04400  ...                0.8\n",
            "Fine-Tuned Flan-T5 + Explicit Injection  0.04400  ...                0.8\n",
            "\n",
            "[3 rows x 4 columns]\n",
            "\n",
            "Detailed results saved to comparison_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4751ff18",
        "outputId": "4098f899-7819-4aec-82d2-7ea4dc08f118"
      },
      "source": [
        "!git status"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch new_data\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mmodels/\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N4XU39cPEr9p"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}