{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "904zHNhPsl7H"
      },
      "source": [
        "# T&C Summarization - Colab Runner\n",
        "\n",
        "Use this notebook to run the training and evaluation remotely on Google Colab (with free GPU)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLFr2AIRsl7I"
      },
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LIMpT9PQsl7I",
        "outputId": "2b0e197d-6f73-4523-fbb4-6b037dec9761",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TandC_Summarisation'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 23 (delta 3), reused 21 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (23/23), 815.66 KiB | 21.46 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "/content/TandC_Summarisation\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/SreeVarshinii/TandC_Summarisation.git\n",
        "%cd TandC_Summarisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n17qy8gjsl7J",
        "outputId": "8fbfa173-de48-466f-84e0-04b7de54aecf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch new_data\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mmodels/\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/train.py --model_name \"models/flan-t5-legal-explained\" --data_path \"data/training/kaggle_legal_augmented.parquet\" --output_dir \"models/flan-t5-kaggle-final\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pxRRFud1QjT",
        "outputId": "aae7be01-0ab6-4033-9d52-378612233146"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-08 07:21:22.243538: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-08 07:21:22.261392: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765178482.283164   11453 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765178482.290002   11453 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765178482.306635   11453 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765178482.306666   11453 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765178482.306669   11453 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765178482.306672   11453 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-08 07:21:22.311701: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading model: models/flan-t5-legal-explained...\n",
            "Loading data from data/training/kaggle_legal_augmented.parquet...\n",
            "Tokenizing data...\n",
            "Map: 100% 7821/7821 [00:20<00:00, 382.53 examples/s]\n",
            "Using existing splits...\n",
            "Filter: 100% 7821/7821 [00:09<00:00, 861.76 examples/s]\n",
            "Filter: 100% 7821/7821 [00:09<00:00, 855.50 examples/s]\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "/content/TandC_Summarisation/src/train.py:80: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n",
            "Starting training on 7721 samples...\n",
            "{'loss': 2.8362, 'grad_norm': 0.7618480324745178, 'learning_rate': 1.966183574879227e-05, 'epoch': 0.05}\n",
            "{'loss': 2.7437, 'grad_norm': 0.7434737086296082, 'learning_rate': 1.9316770186335406e-05, 'epoch': 0.1}\n",
            "{'loss': 2.6818, 'grad_norm': 0.7295796275138855, 'learning_rate': 1.8971704623878537e-05, 'epoch': 0.16}\n",
            "{'loss': 2.6867, 'grad_norm': 0.6732758283615112, 'learning_rate': 1.862663906142167e-05, 'epoch': 0.21}\n",
            "{'loss': 2.6459, 'grad_norm': 0.8374833464622498, 'learning_rate': 1.8281573498964803e-05, 'epoch': 0.26}\n",
            "{'loss': 2.6125, 'grad_norm': 0.6667196154594421, 'learning_rate': 1.7936507936507937e-05, 'epoch': 0.31}\n",
            "{'loss': 2.5937, 'grad_norm': 0.6981863379478455, 'learning_rate': 1.759144237405107e-05, 'epoch': 0.36}\n",
            "{'loss': 2.5384, 'grad_norm': 0.7955964207649231, 'learning_rate': 1.7246376811594206e-05, 'epoch': 0.41}\n",
            "{'loss': 2.5297, 'grad_norm': 0.7134155631065369, 'learning_rate': 1.6901311249137337e-05, 'epoch': 0.47}\n",
            "{'loss': 2.5191, 'grad_norm': 0.7195718288421631, 'learning_rate': 1.655624568668047e-05, 'epoch': 0.52}\n",
            " 17% 500/2898 [11:07<51:52,  1.30s/it]\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/50 [00:00<00:02, 19.46it/s]\u001b[A\n",
            "  8% 4/50 [00:00<00:03, 13.89it/s]\u001b[A\n",
            " 12% 6/50 [00:00<00:03, 11.20it/s]\u001b[A\n",
            " 16% 8/50 [00:00<00:04, 10.15it/s]\u001b[A\n",
            " 20% 10/50 [00:00<00:04,  9.37it/s]\u001b[A\n",
            " 22% 11/50 [00:01<00:04,  9.12it/s]\u001b[A\n",
            " 24% 12/50 [00:01<00:04,  9.02it/s]\u001b[A\n",
            " 26% 13/50 [00:01<00:04,  8.85it/s]\u001b[A\n",
            " 28% 14/50 [00:01<00:04,  8.80it/s]\u001b[A\n",
            " 30% 15/50 [00:01<00:04,  8.67it/s]\u001b[A\n",
            " 34% 17/50 [00:01<00:03,  9.39it/s]\u001b[A\n",
            " 38% 19/50 [00:01<00:03,  9.39it/s]\u001b[A\n",
            " 40% 20/50 [00:02<00:03,  9.24it/s]\u001b[A\n",
            " 44% 22/50 [00:02<00:03,  9.30it/s]\u001b[A\n",
            " 48% 24/50 [00:02<00:02,  9.34it/s]\u001b[A\n",
            " 50% 25/50 [00:02<00:02,  9.11it/s]\u001b[A\n",
            " 52% 26/50 [00:02<00:02,  8.92it/s]\u001b[A\n",
            " 54% 27/50 [00:02<00:02,  8.75it/s]\u001b[A\n",
            " 56% 28/50 [00:02<00:02,  8.65it/s]\u001b[A\n",
            " 58% 29/50 [00:03<00:02,  8.56it/s]\u001b[A\n",
            " 60% 30/50 [00:03<00:02,  8.52it/s]\u001b[A\n",
            " 62% 31/50 [00:03<00:02,  8.44it/s]\u001b[A\n",
            " 64% 32/50 [00:03<00:02,  8.41it/s]\u001b[A\n",
            " 66% 33/50 [00:03<00:02,  8.38it/s]\u001b[A\n",
            " 68% 34/50 [00:03<00:01,  8.34it/s]\u001b[A\n",
            " 70% 35/50 [00:03<00:01,  8.33it/s]\u001b[A\n",
            " 72% 36/50 [00:03<00:01,  8.28it/s]\u001b[A\n",
            " 74% 37/50 [00:04<00:01,  8.33it/s]\u001b[A\n",
            " 76% 38/50 [00:04<00:01,  8.30it/s]\u001b[A\n",
            " 80% 40/50 [00:04<00:01,  9.37it/s]\u001b[A\n",
            " 82% 41/50 [00:04<00:00,  9.08it/s]\u001b[A\n",
            " 86% 43/50 [00:04<00:00,  9.47it/s]\u001b[A\n",
            " 88% 44/50 [00:04<00:00,  9.17it/s]\u001b[A\n",
            " 90% 45/50 [00:04<00:00,  8.95it/s]\u001b[A\n",
            " 92% 46/50 [00:05<00:00,  8.76it/s]\u001b[A\n",
            " 94% 47/50 [00:05<00:00,  8.65it/s]\u001b[A\n",
            " 96% 48/50 [00:05<00:00,  8.55it/s]\u001b[A\n",
            " 98% 49/50 [00:05<00:00,  8.48it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.3931586742401123, 'eval_runtime': 5.6238, 'eval_samples_per_second': 17.782, 'eval_steps_per_second': 8.891, 'epoch': 0.52}\n",
            " 17% 500/2898 [11:13<51:52,  1.30s/it]\n",
            "100% 50/50 [00:05<00:00,  8.52it/s]\u001b[A\n",
            "{'loss': 2.5152, 'grad_norm': 0.8320789337158203, 'learning_rate': 1.6211180124223606e-05, 'epoch': 0.57}\n",
            "{'loss': 2.533, 'grad_norm': 0.6884965896606445, 'learning_rate': 1.5866114561766737e-05, 'epoch': 0.62}\n",
            "{'loss': 2.5001, 'grad_norm': 0.7836073040962219, 'learning_rate': 1.552104899930987e-05, 'epoch': 0.67}\n",
            "{'loss': 2.52, 'grad_norm': 0.6763156652450562, 'learning_rate': 1.5175983436853004e-05, 'epoch': 0.73}\n",
            "{'loss': 2.5121, 'grad_norm': 0.6532737612724304, 'learning_rate': 1.4830917874396135e-05, 'epoch': 0.78}\n",
            "{'loss': 2.4373, 'grad_norm': 0.6878377199172974, 'learning_rate': 1.448585231193927e-05, 'epoch': 0.83}\n",
            "{'loss': 2.4557, 'grad_norm': 0.72659832239151, 'learning_rate': 1.4140786749482403e-05, 'epoch': 0.88}\n",
            "{'loss': 2.51, 'grad_norm': 0.7442845702171326, 'learning_rate': 1.3795721187025537e-05, 'epoch': 0.93}\n",
            "{'loss': 2.4686, 'grad_norm': 0.6770225167274475, 'learning_rate': 1.345065562456867e-05, 'epoch': 0.98}\n",
            "{'loss': 2.4622, 'grad_norm': 0.958430826663971, 'learning_rate': 1.31055900621118e-05, 'epoch': 1.04}\n",
            " 35% 1000/2898 [22:18<42:48,  1.35s/it]\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/50 [00:00<00:02, 19.27it/s]\u001b[A\n",
            "  8% 4/50 [00:00<00:03, 13.71it/s]\u001b[A\n",
            " 12% 6/50 [00:00<00:03, 11.21it/s]\u001b[A\n",
            " 16% 8/50 [00:00<00:04, 10.10it/s]\u001b[A\n",
            " 20% 10/50 [00:00<00:04,  9.40it/s]\u001b[A\n",
            " 22% 11/50 [00:01<00:04,  9.18it/s]\u001b[A\n",
            " 24% 12/50 [00:01<00:04,  8.97it/s]\u001b[A\n",
            " 26% 13/50 [00:01<00:04,  8.78it/s]\u001b[A\n",
            " 28% 14/50 [00:01<00:04,  8.71it/s]\u001b[A\n",
            " 30% 15/50 [00:01<00:04,  8.66it/s]\u001b[A\n",
            " 32% 16/50 [00:01<00:03,  8.97it/s]\u001b[A\n",
            " 36% 18/50 [00:01<00:03,  9.80it/s]\u001b[A\n",
            " 38% 19/50 [00:01<00:03,  9.38it/s]\u001b[A\n",
            " 40% 20/50 [00:02<00:03,  9.16it/s]\u001b[A\n",
            " 44% 22/50 [00:02<00:02,  9.35it/s]\u001b[A\n",
            " 48% 24/50 [00:02<00:02,  9.32it/s]\u001b[A\n",
            " 50% 25/50 [00:02<00:02,  9.09it/s]\u001b[A\n",
            " 52% 26/50 [00:02<00:02,  8.86it/s]\u001b[A\n",
            " 54% 27/50 [00:02<00:02,  8.74it/s]\u001b[A\n",
            " 56% 28/50 [00:02<00:02,  8.62it/s]\u001b[A\n",
            " 58% 29/50 [00:03<00:02,  8.54it/s]\u001b[A\n",
            " 60% 30/50 [00:03<00:02,  8.51it/s]\u001b[A\n",
            " 62% 31/50 [00:03<00:02,  8.44it/s]\u001b[A\n",
            " 64% 32/50 [00:03<00:02,  8.34it/s]\u001b[A\n",
            " 66% 33/50 [00:03<00:02,  8.37it/s]\u001b[A\n",
            " 68% 34/50 [00:03<00:01,  8.34it/s]\u001b[A\n",
            " 70% 35/50 [00:03<00:01,  8.34it/s]\u001b[A\n",
            " 72% 36/50 [00:03<00:01,  8.32it/s]\u001b[A\n",
            " 74% 37/50 [00:04<00:01,  8.33it/s]\u001b[A\n",
            " 76% 38/50 [00:04<00:01,  8.33it/s]\u001b[A\n",
            " 80% 40/50 [00:04<00:01,  9.35it/s]\u001b[A\n",
            " 82% 41/50 [00:04<00:00,  9.05it/s]\u001b[A\n",
            " 86% 43/50 [00:04<00:00,  9.46it/s]\u001b[A\n",
            " 88% 44/50 [00:04<00:00,  9.12it/s]\u001b[A\n",
            " 90% 45/50 [00:04<00:00,  8.95it/s]\u001b[A\n",
            " 92% 46/50 [00:05<00:00,  8.78it/s]\u001b[A\n",
            " 94% 47/50 [00:05<00:00,  8.63it/s]\u001b[A\n",
            " 96% 48/50 [00:05<00:00,  8.53it/s]\u001b[A\n",
            " 98% 49/50 [00:05<00:00,  8.48it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.3326430320739746, 'eval_runtime': 5.6294, 'eval_samples_per_second': 17.764, 'eval_steps_per_second': 8.882, 'epoch': 1.04}\n",
            " 35% 1000/2898 [22:24<42:48,  1.35s/it]\n",
            "100% 50/50 [00:05<00:00,  8.51it/s]\u001b[A\n",
            "{'loss': 2.4653, 'grad_norm': 0.6807287931442261, 'learning_rate': 1.2760524499654935e-05, 'epoch': 1.09}\n",
            "{'loss': 2.4318, 'grad_norm': 0.6367520093917847, 'learning_rate': 1.2415458937198068e-05, 'epoch': 1.14}\n",
            "{'loss': 2.4333, 'grad_norm': 0.578325629234314, 'learning_rate': 1.2070393374741203e-05, 'epoch': 1.19}\n",
            "{'loss': 2.4572, 'grad_norm': 0.7392560839653015, 'learning_rate': 1.1725327812284335e-05, 'epoch': 1.24}\n",
            "{'loss': 2.4086, 'grad_norm': 0.717519223690033, 'learning_rate': 1.1380262249827468e-05, 'epoch': 1.29}\n",
            "{'loss': 2.439, 'grad_norm': 0.8733971118927002, 'learning_rate': 1.1035196687370603e-05, 'epoch': 1.35}\n",
            "{'loss': 2.4568, 'grad_norm': 0.6969101428985596, 'learning_rate': 1.0690131124913734e-05, 'epoch': 1.4}\n",
            "{'loss': 2.4404, 'grad_norm': 0.6708499789237976, 'learning_rate': 1.0345065562456868e-05, 'epoch': 1.45}\n",
            "{'loss': 2.4058, 'grad_norm': 0.8061233758926392, 'learning_rate': 1e-05, 'epoch': 1.5}\n",
            "{'loss': 2.4335, 'grad_norm': 0.8155356049537659, 'learning_rate': 9.654934437543134e-06, 'epoch': 1.55}\n",
            " 52% 1500/2898 [33:32<30:27,  1.31s/it]\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/50 [00:00<00:02, 19.05it/s]\u001b[A\n",
            "  8% 4/50 [00:00<00:03, 13.72it/s]\u001b[A\n",
            " 12% 6/50 [00:00<00:03, 11.17it/s]\u001b[A\n",
            " 16% 8/50 [00:00<00:04, 10.09it/s]\u001b[A\n",
            " 20% 10/50 [00:00<00:04,  9.26it/s]\u001b[A\n",
            " 22% 11/50 [00:01<00:04,  9.19it/s]\u001b[A\n",
            " 24% 12/50 [00:01<00:04,  8.98it/s]\u001b[A\n",
            " 26% 13/50 [00:01<00:04,  8.81it/s]\u001b[A\n",
            " 28% 14/50 [00:01<00:04,  8.78it/s]\u001b[A\n",
            " 30% 15/50 [00:01<00:04,  8.64it/s]\u001b[A\n",
            " 34% 17/50 [00:01<00:03,  9.25it/s]\u001b[A\n",
            " 38% 19/50 [00:01<00:03,  9.44it/s]\u001b[A\n",
            " 40% 20/50 [00:02<00:03,  9.27it/s]\u001b[A\n",
            " 44% 22/50 [00:02<00:02,  9.37it/s]\u001b[A\n",
            " 48% 24/50 [00:02<00:02,  9.34it/s]\u001b[A\n",
            " 50% 25/50 [00:02<00:02,  9.10it/s]\u001b[A\n",
            " 52% 26/50 [00:02<00:02,  8.92it/s]\u001b[A\n",
            " 54% 27/50 [00:02<00:02,  8.74it/s]\u001b[A\n",
            " 56% 28/50 [00:02<00:02,  8.62it/s]\u001b[A\n",
            " 58% 29/50 [00:03<00:02,  8.54it/s]\u001b[A\n",
            " 60% 30/50 [00:03<00:02,  8.49it/s]\u001b[A\n",
            " 62% 31/50 [00:03<00:02,  8.45it/s]\u001b[A\n",
            " 64% 32/50 [00:03<00:02,  8.40it/s]\u001b[A\n",
            " 66% 33/50 [00:03<00:02,  8.34it/s]\u001b[A\n",
            " 68% 34/50 [00:03<00:01,  8.34it/s]\u001b[A\n",
            " 70% 35/50 [00:03<00:01,  8.33it/s]\u001b[A\n",
            " 72% 36/50 [00:03<00:01,  8.31it/s]\u001b[A\n",
            " 74% 37/50 [00:04<00:01,  8.34it/s]\u001b[A\n",
            " 76% 38/50 [00:04<00:01,  8.29it/s]\u001b[A\n",
            " 80% 40/50 [00:04<00:01,  9.28it/s]\u001b[A\n",
            " 82% 41/50 [00:04<00:00,  9.04it/s]\u001b[A\n",
            " 86% 43/50 [00:04<00:00,  9.45it/s]\u001b[A\n",
            " 88% 44/50 [00:04<00:00,  9.16it/s]\u001b[A\n",
            " 90% 45/50 [00:04<00:00,  8.86it/s]\u001b[A\n",
            " 92% 46/50 [00:05<00:00,  8.72it/s]\u001b[A\n",
            " 94% 47/50 [00:05<00:00,  8.62it/s]\u001b[A\n",
            " 96% 48/50 [00:05<00:00,  8.53it/s]\u001b[A\n",
            " 98% 49/50 [00:05<00:00,  8.46it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.3016207218170166, 'eval_runtime': 5.6358, 'eval_samples_per_second': 17.744, 'eval_steps_per_second': 8.872, 'epoch': 1.55}\n",
            " 52% 1500/2898 [33:38<30:27,  1.31s/it]\n",
            "100% 50/50 [00:05<00:00,  8.49it/s]\u001b[A\n",
            "{'loss': 2.4261, 'grad_norm': 0.8651257753372192, 'learning_rate': 9.309868875086268e-06, 'epoch': 1.61}\n",
            "{'loss': 2.4024, 'grad_norm': 0.8656449913978577, 'learning_rate': 8.964803312629399e-06, 'epoch': 1.66}\n",
            "{'loss': 2.3891, 'grad_norm': 0.779435396194458, 'learning_rate': 8.619737750172534e-06, 'epoch': 1.71}\n",
            "{'loss': 2.4297, 'grad_norm': 0.766266405582428, 'learning_rate': 8.274672187715666e-06, 'epoch': 1.76}\n",
            "{'loss': 2.4538, 'grad_norm': 0.8039397597312927, 'learning_rate': 7.9296066252588e-06, 'epoch': 1.81}\n",
            "{'loss': 2.3851, 'grad_norm': 0.6055313348770142, 'learning_rate': 7.584541062801934e-06, 'epoch': 1.86}\n",
            "{'loss': 2.4156, 'grad_norm': 0.6473417282104492, 'learning_rate': 7.2394755003450655e-06, 'epoch': 1.92}\n",
            "{'loss': 2.4196, 'grad_norm': 0.7507883310317993, 'learning_rate': 6.894409937888199e-06, 'epoch': 1.97}\n",
            "{'loss': 2.456, 'grad_norm': 0.6389470100402832, 'learning_rate': 6.549344375431333e-06, 'epoch': 2.02}\n",
            "{'loss': 2.4074, 'grad_norm': 0.6494154930114746, 'learning_rate': 6.2042788129744655e-06, 'epoch': 2.07}\n",
            " 69% 2000/2898 [44:44<19:57,  1.33s/it]\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/50 [00:00<00:02, 19.25it/s]\u001b[A\n",
            "  8% 4/50 [00:00<00:03, 13.88it/s]\u001b[A\n",
            " 12% 6/50 [00:00<00:03, 11.14it/s]\u001b[A\n",
            " 16% 8/50 [00:00<00:04, 10.14it/s]\u001b[A\n",
            " 20% 10/50 [00:00<00:04,  9.43it/s]\u001b[A\n",
            " 22% 11/50 [00:01<00:04,  9.18it/s]\u001b[A\n",
            " 24% 12/50 [00:01<00:04,  8.99it/s]\u001b[A\n",
            " 26% 13/50 [00:01<00:04,  8.80it/s]\u001b[A\n",
            " 28% 14/50 [00:01<00:04,  8.75it/s]\u001b[A\n",
            " 30% 15/50 [00:01<00:04,  8.65it/s]\u001b[A\n",
            " 32% 16/50 [00:01<00:03,  8.99it/s]\u001b[A\n",
            " 36% 18/50 [00:01<00:03,  9.80it/s]\u001b[A\n",
            " 38% 19/50 [00:01<00:03,  9.39it/s]\u001b[A\n",
            " 40% 20/50 [00:02<00:03,  9.19it/s]\u001b[A\n",
            " 44% 22/50 [00:02<00:02,  9.37it/s]\u001b[A\n",
            " 48% 24/50 [00:02<00:02,  9.26it/s]\u001b[A\n",
            " 50% 25/50 [00:02<00:02,  9.10it/s]\u001b[A\n",
            " 52% 26/50 [00:02<00:02,  8.88it/s]\u001b[A\n",
            " 54% 27/50 [00:02<00:02,  8.72it/s]\u001b[A\n",
            " 56% 28/50 [00:02<00:02,  8.62it/s]\u001b[A\n",
            " 58% 29/50 [00:03<00:02,  8.46it/s]\u001b[A\n",
            " 60% 30/50 [00:03<00:02,  8.50it/s]\u001b[A\n",
            " 62% 31/50 [00:03<00:02,  8.44it/s]\u001b[A\n",
            " 64% 32/50 [00:03<00:02,  8.36it/s]\u001b[A\n",
            " 66% 33/50 [00:03<00:02,  8.39it/s]\u001b[A\n",
            " 68% 34/50 [00:03<00:01,  8.34it/s]\u001b[A\n",
            " 70% 35/50 [00:03<00:01,  8.31it/s]\u001b[A\n",
            " 72% 36/50 [00:03<00:01,  8.32it/s]\u001b[A\n",
            " 74% 37/50 [00:04<00:01,  8.32it/s]\u001b[A\n",
            " 76% 38/50 [00:04<00:01,  8.33it/s]\u001b[A\n",
            " 80% 40/50 [00:04<00:01,  9.33it/s]\u001b[A\n",
            " 82% 41/50 [00:04<00:01,  8.96it/s]\u001b[A\n",
            " 86% 43/50 [00:04<00:00,  9.40it/s]\u001b[A\n",
            " 88% 44/50 [00:04<00:00,  9.15it/s]\u001b[A\n",
            " 90% 45/50 [00:04<00:00,  8.91it/s]\u001b[A\n",
            " 92% 46/50 [00:05<00:00,  8.78it/s]\u001b[A\n",
            " 94% 47/50 [00:05<00:00,  8.63it/s]\u001b[A\n",
            " 96% 48/50 [00:05<00:00,  8.55it/s]\u001b[A\n",
            " 98% 49/50 [00:05<00:00,  8.48it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.2854926586151123, 'eval_runtime': 5.6313, 'eval_samples_per_second': 17.758, 'eval_steps_per_second': 8.879, 'epoch': 2.07}\n",
            " 69% 2000/2898 [44:50<19:57,  1.33s/it]\n",
            "100% 50/50 [00:05<00:00,  8.51it/s]\u001b[A\n",
            "{'loss': 2.4029, 'grad_norm': 0.7002553939819336, 'learning_rate': 5.859213250517599e-06, 'epoch': 2.12}\n",
            "{'loss': 2.4154, 'grad_norm': 0.699020504951477, 'learning_rate': 5.514147688060733e-06, 'epoch': 2.17}\n",
            "{'loss': 2.3498, 'grad_norm': 0.6950993537902832, 'learning_rate': 5.169082125603865e-06, 'epoch': 2.23}\n",
            "{'loss': 2.4015, 'grad_norm': 0.621418833732605, 'learning_rate': 4.824016563146998e-06, 'epoch': 2.28}\n",
            "{'loss': 2.3959, 'grad_norm': 0.7256790995597839, 'learning_rate': 4.478951000690132e-06, 'epoch': 2.33}\n",
            "{'loss': 2.4245, 'grad_norm': 0.579210102558136, 'learning_rate': 4.133885438233265e-06, 'epoch': 2.38}\n",
            "{'loss': 2.3749, 'grad_norm': 0.6253811717033386, 'learning_rate': 3.788819875776398e-06, 'epoch': 2.43}\n",
            "{'loss': 2.396, 'grad_norm': 0.7858520150184631, 'learning_rate': 3.443754313319531e-06, 'epoch': 2.48}\n",
            "{'loss': 2.3873, 'grad_norm': 0.6209303140640259, 'learning_rate': 3.098688750862664e-06, 'epoch': 2.54}\n",
            "{'loss': 2.3932, 'grad_norm': 0.8568459749221802, 'learning_rate': 2.7536231884057974e-06, 'epoch': 2.59}\n",
            " 86% 2500/2898 [55:59<08:47,  1.33s/it]\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/50 [00:00<00:02, 19.18it/s]\u001b[A\n",
            "  8% 4/50 [00:00<00:03, 13.78it/s]\u001b[A\n",
            " 12% 6/50 [00:00<00:03, 11.15it/s]\u001b[A\n",
            " 16% 8/50 [00:00<00:04, 10.11it/s]\u001b[A\n",
            " 20% 10/50 [00:00<00:04,  9.40it/s]\u001b[A\n",
            " 22% 11/50 [00:01<00:04,  9.16it/s]\u001b[A\n",
            " 24% 12/50 [00:01<00:04,  8.96it/s]\u001b[A\n",
            " 26% 13/50 [00:01<00:04,  8.79it/s]\u001b[A\n",
            " 28% 14/50 [00:01<00:04,  8.76it/s]\u001b[A\n",
            " 30% 15/50 [00:01<00:04,  8.65it/s]\u001b[A\n",
            " 34% 17/50 [00:01<00:03,  9.39it/s]\u001b[A\n",
            " 38% 19/50 [00:01<00:03,  9.41it/s]\u001b[A\n",
            " 40% 20/50 [00:02<00:03,  9.26it/s]\u001b[A\n",
            " 44% 22/50 [00:02<00:02,  9.36it/s]\u001b[A\n",
            " 48% 24/50 [00:02<00:02,  9.32it/s]\u001b[A\n",
            " 50% 25/50 [00:02<00:02,  9.12it/s]\u001b[A\n",
            " 52% 26/50 [00:02<00:02,  8.93it/s]\u001b[A\n",
            " 54% 27/50 [00:02<00:02,  8.76it/s]\u001b[A\n",
            " 56% 28/50 [00:02<00:02,  8.64it/s]\u001b[A\n",
            " 58% 29/50 [00:03<00:02,  8.55it/s]\u001b[A\n",
            " 60% 30/50 [00:03<00:02,  8.51it/s]\u001b[A\n",
            " 62% 31/50 [00:03<00:02,  8.44it/s]\u001b[A\n",
            " 64% 32/50 [00:03<00:02,  8.41it/s]\u001b[A\n",
            " 66% 33/50 [00:03<00:02,  8.37it/s]\u001b[A\n",
            " 68% 34/50 [00:03<00:01,  8.36it/s]\u001b[A\n",
            " 70% 35/50 [00:03<00:01,  8.36it/s]\u001b[A\n",
            " 72% 36/50 [00:03<00:01,  8.33it/s]\u001b[A\n",
            " 74% 37/50 [00:04<00:01,  8.35it/s]\u001b[A\n",
            " 76% 38/50 [00:04<00:01,  8.33it/s]\u001b[A\n",
            " 80% 40/50 [00:04<00:01,  9.34it/s]\u001b[A\n",
            " 82% 41/50 [00:04<00:00,  9.04it/s]\u001b[A\n",
            " 86% 43/50 [00:04<00:00,  9.46it/s]\u001b[A\n",
            " 88% 44/50 [00:04<00:00,  9.16it/s]\u001b[A\n",
            " 90% 45/50 [00:04<00:00,  8.93it/s]\u001b[A\n",
            " 92% 46/50 [00:05<00:00,  8.76it/s]\u001b[A\n",
            " 94% 47/50 [00:05<00:00,  8.63it/s]\u001b[A\n",
            " 96% 48/50 [00:05<00:00,  8.53it/s]\u001b[A\n",
            " 98% 49/50 [00:05<00:00,  8.41it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.2757174968719482, 'eval_runtime': 5.6261, 'eval_samples_per_second': 17.774, 'eval_steps_per_second': 8.887, 'epoch': 2.59}\n",
            " 86% 2500/2898 [56:05<08:47,  1.33s/it]\n",
            "100% 50/50 [00:05<00:00,  8.51it/s]\u001b[A\n",
            "{'loss': 2.3816, 'grad_norm': 0.7366504073143005, 'learning_rate': 2.4085576259489306e-06, 'epoch': 2.64}\n",
            "{'loss': 2.3982, 'grad_norm': 0.7297586798667908, 'learning_rate': 2.0634920634920634e-06, 'epoch': 2.69}\n",
            "{'loss': 2.3986, 'grad_norm': 0.6716880202293396, 'learning_rate': 1.718426501035197e-06, 'epoch': 2.74}\n",
            "{'loss': 2.3898, 'grad_norm': 0.7773165702819824, 'learning_rate': 1.37336093857833e-06, 'epoch': 2.8}\n",
            "{'loss': 2.4034, 'grad_norm': 0.5845457911491394, 'learning_rate': 1.0282953761214632e-06, 'epoch': 2.85}\n",
            "{'loss': 2.373, 'grad_norm': 0.7677854895591736, 'learning_rate': 6.832298136645964e-07, 'epoch': 2.9}\n",
            "{'loss': 2.3972, 'grad_norm': 0.6508705019950867, 'learning_rate': 3.3816425120772945e-07, 'epoch': 2.95}\n",
            "{'train_runtime': 3898.1898, 'train_samples_per_second': 5.942, 'train_steps_per_second': 0.743, 'train_loss': 2.464015865918272, 'epoch': 3.0}\n",
            "100% 2898/2898 [1:04:58<00:00,  1.35s/it]\n",
            "Saving model to models/flan-t5-kaggle-final...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/compare_models.py --model_path \"models/flan-t5-legal-explained\" --data_path \"data/training/kaggle_legal_augmented.parquet\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F_6O_f71Vd8",
        "outputId": "c03a4db6-01c7-4fd8-cdbe-67eb1f01b66d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Evaluated Model: models/flan-t5-legal-explained...\n",
            "Loading model: models/flan-t5-legal-explained...\n",
            "2025-12-08 08:30:15.785885: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-08 08:30:15.804194: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765182615.825983   28859 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765182615.832585   28859 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765182615.849441   28859 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765182615.849472   28859 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765182615.849475   28859 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765182615.849477   28859 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-08 08:30:15.854403: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Model loaded on cuda.\n",
            "Loaded glossary with 50 terms.\n",
            "Loading BART (Baseline)...\n",
            "Loading data from data/training/kaggle_legal_augmented.parquet...\n",
            "\n",
            "--- Running Comparison on 5 samples ---\n",
            "100% 5/5 [00:11<00:00,  2.31s/it]\n",
            "\n",
            "--- Aggregated Results ---\n",
            "                                          rouge1  ...  explanation_count\n",
            "model                                             ...                   \n",
            "BART (Baseline)                          0.10516  ...                0.0\n",
            "Fine-Tuned Flan-T5                       0.04400  ...                0.8\n",
            "Fine-Tuned Flan-T5 + Explicit Injection  0.04400  ...                0.8\n",
            "\n",
            "[3 rows x 4 columns]\n",
            "\n",
            "Detailed results saved to comparison_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4751ff18",
        "outputId": "4098f899-7819-4aec-82d2-7ea4dc08f118"
      },
      "source": [
        "!git status"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch new_data\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mmodels/\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N4XU39cPEr9p"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}